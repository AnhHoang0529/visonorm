# ğŸ“¦ ViSoNorm Toolkit â€” Vietnamese Text Normalization & Processing

**ViSoNorm** lÃ  má»™t toolkit chuyÃªn biá»‡t dÃ nh cho **chuáº©n hÃ³a vÃ  xá»­ lÃ½ vÄƒn báº£n tiáº¿ng Viá»‡t**, Ä‘Æ°á»£c thiáº¿t káº¿ tá»‘i Æ°u cho mÃ´i trÆ°á»ng **NLP** vÃ  dá»… dÃ ng cÃ i Ä‘áº·t qua **PyPI**. CÃ¡c tÃ i nguyÃªn (datasets, models) Ä‘Æ°á»£c lÆ°u trá»¯ vÃ  quáº£n lÃ½ trá»±c tiáº¿p trÃªn **Hugging Face Hub** vÃ  **GitHub Releases**.

[![PyPI version](https://badge.fury.io/py/visonorm.svg)](https://badge.fury.io/py/visonorm)
[![Python 3.10+](https://img.shields.io/badge/python-3.10+-blue.svg)](https://www.python.org/downloads/)
[![License: MIT](https://img.shields.io/badge/License-MIT-yellow.svg)](https://opensource.org/licenses/MIT)

---

## ğŸš€ TÃ­nh nÄƒng chÃ­nh

### 1. ğŸ”§ **BasicNormalizer** â€” Chuáº©n hÃ³a vÄƒn báº£n cÆ¡ báº£n

* **Case folding**: chuyá»ƒn toÃ n bá»™ vÄƒn báº£n vá» lowercase/uppercase/capitalize.
* **Tone normalization**: chuáº©n hÃ³a dáº¥u thanh tiáº¿ng Viá»‡t.
* **Basic preprocessing**: loáº¡i bá» khoáº£ng tráº¯ng thá»«a, kÃ½ tá»± Ä‘áº·c biá»‡t, Ä‘á»‹nh dáº¡ng cÃ¢u.

### 2. ğŸ˜€ **EmojiHandler** â€” Xá»­ lÃ½ emoji

* **Detect emojis**: phÃ¡t hiá»‡n emoji trong vÄƒn báº£n.
* **Split emoji text**: tÃ¡ch emoji ra khá»i cÃ¢u.
* **Remove emojis**: loáº¡i bá» toÃ n bá»™ emoji.

### 3. âœï¸ **Lexical Normalization** â€” Chuáº©n hÃ³a vÄƒn báº£n máº¡ng xÃ£ há»™i

* **ViSoLexNormalizer**: Chuáº©n hÃ³a vÄƒn báº£n sá»­ dá»¥ng mÃ´ hÃ¬nh deep learning tá»« HuggingFace.
* **NswDetector**: PhÃ¡t hiá»‡n tá»« phi chuáº©n (non-standard words).
* **detect_nsw()**: HÃ m tiá»‡n Ã­ch Ä‘á»ƒ phÃ¡t hiá»‡n NSW.
* **normalize_sentence()**: HÃ m tiá»‡n Ã­ch Ä‘á»ƒ chuáº©n hÃ³a cÃ¢u.

### 4. ğŸ“Š **Resource Management** â€” Quáº£n lÃ½ dá»¯ liá»‡u

* `list_datasets()` â€” Liá»‡t kÃª datasets cÃ³ sáºµn.
* `load_dataset()` â€” Táº£i dataset tá»« GitHub Releases.
* `get_dataset_info()` â€” Xem thÃ´ng tin chi tiáº¿t dataset.

### 5. ğŸ§  **Task Models** â€” MÃ´ hÃ¬nh xá»­ lÃ½ tÃ¡c vá»¥

* **SpamReviewDetection** â€” PhÃ¡t hiá»‡n spam.
* **HateSpeechDetection** â€” PhÃ¡t hiá»‡n hate speech.
* **HateSpeechSpanDetection** â€” PhÃ¡t hiá»‡n span cá»§a hate speech.
* **EmotionRecognition** â€” Nháº­n diá»‡n cáº£m xÃºc.
* **AspectSentimentAnalysis** â€” PhÃ¢n tÃ­ch sentiment theo tá»«ng khÃ­a cáº¡nh.

---

## ğŸ“¥ CÃ i Ä‘áº·t

### CÃ i Ä‘áº·t tá»« PyPI (Khuyáº¿n nghá»‹)

```bash
pip install visonorm
```

### Requirements

- Python >= 3.10
- PyTorch >= 1.10.0
- Transformers >= 4.0.0
- scikit-learn >= 0.24.0
- pandas >= 1.3.0

---

## ğŸ“š HÆ°á»›ng dáº«n sá»­ dá»¥ng

### 1. ğŸ”§ BasicNormalizer â€” Chuáº©n hÃ³a vÄƒn báº£n cÆ¡ báº£n

```python
from visonorm import BasicNormalizer

# Khá»Ÿi táº¡o BasicNormalizer
normalizer = BasicNormalizer()

# VÃ­ dá»¥ vÄƒn báº£n
text = "HÃ´m nay tÃ´i ráº¥t VUI ğŸ˜Š vÃ  Háº NH PHÃšC ğŸ‰!"

# Case folding
print(normalizer.case_folding(text, mode='lower'))
# Output: hÃ´m nay tÃ´i ráº¥t vui ğŸ˜Š vÃ  háº¡nh phÃºc ğŸ‰!

print(normalizer.case_folding(text, mode='upper'))
# Output: HÃ”M NAY TÃ”I Ráº¤T VUI ğŸ˜Š VÃ€ Háº NH PHÃšC ğŸ‰!

print(normalizer.case_folding(text, mode='capitalize'))
# Output: HÃ´m Nay TÃ´i Ráº¥t Vui ğŸ˜Š VÃ  Háº¡nh PhÃºc ğŸ‰!

# Tone normalization
text2 = "Báº­n xong rá»“i. XoÃ£ Ä‘i :)"
print(normalizer.tone_normalization(text2))
# Output: Báº­n xong rá»“i. XÃµa Ä‘i :)

# Basic normalization vá»›i cÃ¡c tÃ¹y chá»n
normalized = normalizer.basic_normalizer(
    text,
    case_folding=True,
    mode='lower',
    remove_emoji=False,
    split_emoji=True
)
print(normalized)
# Output: ['hÃ´m', 'nay', 'tÃ´i', 'ráº¥t', 'vui', 'ğŸ˜Š', 'vÃ ', 'háº¡nh', 'phÃºc', 'ğŸ‰', '!']

# Loáº¡i bá» emoji
normalized_no_emoji = normalizer.basic_normalizer(
    text,
    case_folding=True,
    remove_emoji=True
)
print(normalized_no_emoji)
# Output: ['hÃ´m', 'nay', 'tÃ´i', 'ráº¥t', 'vui', 'vÃ ', 'háº¡nh', 'phÃºc', '!']
```

### 2. ğŸ˜Š EmojiHandler â€” Xá»­ lÃ½ emoji

```python
from visonorm import EmojiHandler

# Khá»Ÿi táº¡o EmojiHandler
emoji_handler = EmojiHandler()

text = "HÃ´m nay tÃ´i ráº¥t vui ğŸ˜ŠğŸ‰ğŸ˜Š vÃ  háº¡nh phÃºc ğŸ‰!"

# Detect emojis
emojis = emoji_handler.detect_emoji(text)
print(f"Detected emojis: {emojis}")
# Output: Detected emojis: ['ğŸ˜ŠğŸ‰ğŸ˜Š', 'ğŸ‰']

# Split emoji text
split_text = emoji_handler.split_emoji_text(text)
print(f"Split emoji text: {split_text}")
# Output: HÃ´m nay tÃ´i ráº¥t vui ğŸ˜Š ğŸ‰ ğŸ˜Š vÃ  háº¡nh phÃºc ğŸ‰ !

# Split consecutive emojis
text_consecutive = "HÃ´m nay tÃ´i ráº¥t vui ğŸ˜ŠğŸ‰ğŸ˜Š"
split_consecutive = emoji_handler.split_emoji_emoji(text_consecutive)
print(f"Split consecutive: {split_consecutive}")
# Output: HÃ´m nay tÃ´i ráº¥t vui ğŸ˜Š ğŸ‰ ğŸ˜Š

# Remove emojis
text_no_emoji = emoji_handler.remove_emojis(text)
print(f"Text without emojis: {text_no_emoji}")
# Output: HÃ´m nay tÃ´i ráº¥t vui vÃ  háº¡nh phÃºc !
```

### 3. âœï¸ Lexical Normalization â€” Chuáº©n hÃ³a vÄƒn báº£n máº¡ng xÃ£ há»™i

#### Sá»­ dá»¥ng ViSoLexNormalizer

```python
from visonorm import ViSoLexNormalizer

# Khá»Ÿi táº¡o vá»›i model máº·c Ä‘á»‹nh (hadung1802/vit5-base-normalizer-mix100)
normalizer = ViSoLexNormalizer()

# Hoáº·c chá»‰ Ä‘á»‹nh model cá»¥ thá»ƒ tá»« HuggingFace
# normalizer = ViSoLexNormalizer(model_repo="hadung1802/visobert-normalizer-mix100")
# normalizer = ViSoLexNormalizer(model_repo="hadung1802/bartpho-normalizer-mix100")

# Chuáº©n hÃ³a cÃ¢u
input_str = "sv dh gia dinh chua cho di lam :))"
normalized = normalizer.normalize_sentence(input_str)
print(f"Original: {input_str}")
print(f"Normalized: {normalized}")
# Output:
# Original: sv dh gia dinh chua cho di lam :))
# Normalized: sinh viÃªn Ä‘áº¡i há»c gia Ä‘Ã¬nh chÆ°a cho Ä‘i lÃ m :))

# Chuáº©n hÃ³a vÃ  phÃ¡t hiá»‡n NSW cÃ¹ng lÃºc
nsw_spans, normalized_text = normalizer.normalize_sentence(input_str, detect_nsw=True)
print(f"Normalized: {normalized_text}")
print("Detected NSW:")
for nsw in nsw_spans:
    print(f"  - '{nsw['nsw']}' â†’ '{nsw['prediction']}' (confidence: {nsw['confidence_score']})")
# Output:
# Normalized: sinh viÃªn Ä‘áº¡i há»c gia Ä‘Ã¬nh chÆ°a cho Ä‘i lÃ m :))
# Detected NSW:
#   - 'sv' â†’ 'sinh viÃªn' (confidence: 1.0)
#   - 'dh' â†’ 'Ä‘áº¡i há»c' (confidence: 1.0)
#   - 'dinh' â†’ 'Ä‘Ã¬nh' (confidence: 1.0)
#   - 'chua' â†’ 'chÆ°a' (confidence: 1.0)
#   - 'di' â†’ 'Ä‘i' (confidence: 1.0)
#   - 'lam' â†’ 'lÃ m' (confidence: 1.0)
```

#### Sá»­ dá»¥ng NswDetector

```python
from visonorm import NswDetector

# Khá»Ÿi táº¡o detector
detector = NswDetector()

# PhÃ¡t hiá»‡n NSW
input_str = "sv dh gia dinh chua cho di lam"
nsw_spans = detector.detect_nsw(input_str)
for nsw in nsw_spans:
    print(f"NSW: '{nsw['nsw']}' â†’ '{nsw['prediction']}' (confidence: {nsw['confidence_score']})")
```

#### Sá»­ dá»¥ng hÃ m tiá»‡n Ã­ch

```python
from visonorm import detect_nsw, normalize_sentence

# PhÃ¡t hiá»‡n NSW
nsw_spans = detect_nsw("sv dh gia dinh chua cho di lam")

# Chuáº©n hÃ³a cÃ¢u
normalized = normalize_sentence("sv dh gia dinh chua cho di lam")

# Chuáº©n hÃ³a vÃ  phÃ¡t hiá»‡n NSW
nsw_spans, normalized = normalize_sentence("sv dh gia dinh chua cho di lam", detect_nsw=True)
```

### 4. ğŸ“Š Resource Management â€” Quáº£n lÃ½ dataset

CÃ¡c dataset Ä‘Æ°á»£c lÆ°u trá»¯ trÃªn **GitHub Releases** vÃ  tá»± Ä‘á»™ng táº£i vá» khi cáº§n.

```python
from visonorm import list_datasets, load_dataset, get_dataset_info

# Liá»‡t kÃª táº¥t cáº£ datasets cÃ³ sáºµn
datasets = list_datasets()
print("Available datasets:")
for i, dataset in enumerate(datasets, 1):
    print(f"{i}. {dataset}")

# Láº¥y thÃ´ng tin chi tiáº¿t vá» má»™t dataset
info = get_dataset_info("ViLexNorm")
print(f"URL: {info['url']}")
print(f"Type: {info['type']}")

# Táº£i dataset (tá»± Ä‘á»™ng cache)
df = load_dataset("ViLexNorm")
print(f"Dataset shape: {df.shape}")
print(df.head())

# Force download láº¡i dataset
df = load_dataset("ViLexNorm", force_download=True)
```

**CÃ¡c datasets cÃ³ sáºµn:**

- **ViLexNorm**: Vietnamese Lexical Normalization Dataset
- **ViHSD**: Vietnamese Hate Speech Detection Dataset
- **ViHOS**: Vietnamese Hate and Offensive Speech Dataset
- **UIT-VSMEC**: Vietnamese Social Media Emotion Corpus
- **ViSpamReviews**: Vietnamese Spam Review Detection Dataset
- **UIT-ViSFD**: Vietnamese Sentiment and Emotion Detection Dataset
- **UIT-ViCTSD**: Vietnamese Customer Review Sentiment Dataset
- **ViTHSD**: Vietnamese Toxic Hate Speech Detection Dataset
- **BKEE**: Vietnamese Emotion Recognition Dataset
- **UIT-ViQuAD**: Vietnamese Question Answering Dataset

### 5. ğŸ§  Task Models â€” MÃ´ hÃ¬nh xá»­ lÃ½ tÃ¡c vá»¥

Táº¥t cáº£ cÃ¡c mÃ´ hÃ¬nh task Ä‘Æ°á»£c lÆ°u trá»¯ trÃªn **HuggingFace Hub** táº¡i [https://huggingface.co/visolex](https://huggingface.co/visolex).

#### SpamReviewDetection â€” PhÃ¡t hiá»‡n spam

```python
from visonorm import SpamReviewDetection

# Xem danh sÃ¡ch cÃ¡c model cÃ³ sáºµn
models = SpamReviewDetection.list_models()
print("Available models:", SpamReviewDetection.list_model_names())

# Khá»Ÿi táº¡o vá»›i model phobert-v1 (binary classification)
spam_detector = SpamReviewDetection("phobert-v1")

# Hoáº·c sá»­ dá»¥ng cÃ¡c model khÃ¡c
# spam_detector = SpamReviewDetection("phobert-v1-multiclass")  # Multiclass model

# PhÃ¡t hiá»‡n spam
text = "Sáº£n pháº©m ráº¥t tá»‘t, cháº¥t lÆ°á»£ng cao!"
result = spam_detector.predict(text)
print(f"Text: {text}")
print(f"Result: {result}")
# Output: Result: Non-spam
```

#### HateSpeechDetection â€” PhÃ¡t hiá»‡n hate speech

```python
from visonorm import HateSpeechDetection

# Xem danh sÃ¡ch cÃ¡c model cÃ³ sáºµn
print("Available models:", HateSpeechDetection.list_model_names())

# Khá»Ÿi táº¡o detector
hate_detector = HateSpeechDetection("phobert-v1")
# Hoáº·c: HateSpeechDetection("phobert-v2"), HateSpeechDetection("visobert"), etc.

# PhÃ¡t hiá»‡n hate speech
text = "VÄƒn báº£n cáº§n kiá»ƒm tra hate speech"
result = hate_detector.predict(text)
print(f"Result: {result}")
# Output: Result: CLEAN
```

#### HateSpeechSpanDetection â€” PhÃ¡t hiá»‡n span cá»§a hate speech

```python
from visonorm import HateSpeechSpanDetection

# Xem danh sÃ¡ch cÃ¡c model cÃ³ sáºµn
print("Available models:", HateSpeechSpanDetection.list_model_names())

# Khá»Ÿi táº¡o detector
hate_span_detector = HateSpeechSpanDetection("phobert-v1")
# Hoáº·c: HateSpeechSpanDetection("vihate-t5"), HateSpeechSpanDetection("visobert"), etc.

# PhÃ¡t hiá»‡n span
text = "NÃ³i cÃ¡i lá»“n gÃ¬ mÃ  khÃ³ nghe"
result = hate_span_detector.predict(text)
print(f"Result: {result}")
# Output: {'tokens': [...], 'text': '...'}
```

#### EmotionRecognition â€” Nháº­n diá»‡n cáº£m xÃºc

```python
from visonorm import EmotionRecognition

# Xem danh sÃ¡ch cÃ¡c model cÃ³ sáºµn
print("Available models:", EmotionRecognition.list_model_names())

# Khá»Ÿi táº¡o detector
emotion_detector = EmotionRecognition("phobert-v2")
# Hoáº·c: EmotionRecognition("phobert-v1"), EmotionRecognition("visobert"), etc.

# Nháº­n diá»‡n cáº£m xÃºc
text = "TÃ´i ráº¥t vui má»«ng vÃ  háº¡nh phÃºc!"
emotion = emotion_detector.predict(text)
print(f"Emotion: {emotion}")
# Output: Emotion: Enjoyment
```

#### AspectSentimentAnalysis â€” PhÃ¢n tÃ­ch sentiment theo aspect

```python
from visonorm import AspectSentimentAnalysis

# Xem danh sÃ¡ch cÃ¡c domain cÃ³ sáºµn
print("Available domains:", AspectSentimentAnalysis.list_domains())

# Xem danh sÃ¡ch cÃ¡c model cho má»™t domain cá»¥ thá»ƒ
print("Models for smartphone:", AspectSentimentAnalysis.list_model_names("smartphone"))
print("Models for restaurant:", AspectSentimentAnalysis.list_model_names("restaurant"))
print("Models for hotel:", AspectSentimentAnalysis.list_model_names("hotel"))

# Khá»Ÿi táº¡o vá»›i domain smartphone vÃ  model phobert
absa = AspectSentimentAnalysis("smartphone", "phobert")
# Hoáº·c sá»­ dá»¥ng cÃ¡c model khÃ¡c: "phobert-v2", "bartpho", "vit5", "visobert", etc.

# Hoáº·c cÃ¡c domain khÃ¡c
# absa = AspectSentimentAnalysis("restaurant", "phobert-v1")
# absa = AspectSentimentAnalysis("hotel", "phobert-v1")

# PhÃ¢n tÃ­ch sentiment
text = "Äiá»‡n thoáº¡i cÃ³ camera ráº¥t tá»‘t nhÆ°ng pin nhanh háº¿t"
aspects = absa.predict(text, threshold=0.25)
print(f"Aspects: {aspects}")
# Output: [('BATTERY', 'neutral'), ('FEATURES', 'neutral'), ('PERFORMANCE', 'positive'), ...]
```

### 6. ğŸ¯ Advanced Usage â€” Sá»­ dá»¥ng nÃ¢ng cao

#### Káº¿t há»£p nhiá»u chá»©c nÄƒng

```python
from visonorm import BasicNormalizer, EmojiHandler, ViSoLexNormalizer

def process_text_advanced(text):
    """Xá»­ lÃ½ vÄƒn báº£n vá»›i nhiá»u bÆ°á»›c"""
    print(f"Original text: {text}")
    
    # BÆ°á»›c 1: Xá»­ lÃ½ emoji
    emoji_handler = EmojiHandler()
    emojis = emoji_handler.detect_emoji(text)
    print(f"Detected emojis: {emojis}")
    
    # BÆ°á»›c 2: Chuáº©n hÃ³a cÆ¡ báº£n
    normalizer = BasicNormalizer()
    normalized = normalizer.basic_normalizer(text, case_folding=True)
    print(f"Basic normalized: {normalized}")
    
    # BÆ°á»›c 3: Chuáº©n hÃ³a lexical vá»›i deep learning
    lex_normalizer = ViSoLexNormalizer()
    final_normalized = lex_normalizer.normalize_sentence(text)
    print(f"Lexical normalized: {final_normalized}")
    
    return {
        'original': text,
        'emojis': emojis,
        'basic_normalized': normalized,
        'lexical_normalized': final_normalized
    }

# Test
result = process_text_advanced("HÃ´m nay tÃ´i ráº¥tğŸ˜Š VUI ğŸ˜ŠğŸ˜Š vÃ  Háº NH PHÃšC!")
```

---

## ğŸŒ Resources

### HuggingFace Hub

Táº¥t cáº£ cÃ¡c mÃ´ hÃ¬nh vÃ  resources Ä‘Æ°á»£c publish trÃªn HuggingFace Hub:

- **Organization**: [https://huggingface.co/visolex](https://huggingface.co/visolex)
- **Models**: Xem danh sÃ¡ch Ä‘áº§y Ä‘á»§ táº¡i [https://huggingface.co/visolex](https://huggingface.co/visolex)

**CÃ¡c mÃ´ hÃ¬nh normalization cÃ³ sáºµn:**

- `visolex/visobert-normalizer-mix100` (máº·c Ä‘á»‹nh)


### GitHub Releases

CÃ¡c datasets Ä‘Æ°á»£c lÆ°u trá»¯ dÆ°á»›i dáº¡ng GitHub Releases vÃ  tá»± Ä‘á»™ng táº£i vá» khi sá»­ dá»¥ng:

- **Repository**: [https://github.com/AnhHoang0529/visonorm](https://github.com/AnhHoang0529/visonorm)
- **Releases**: [https://github.com/AnhHoang0529/visonorm/releases](https://github.com/AnhHoang0529/visonorm/releases)

---

## ğŸ“– API Reference

### Core Components

#### BasicNormalizer

```python
normalizer = BasicNormalizer()

# Methods
normalizer.case_folding(text, mode='lower')  # 'lower', 'upper', 'capitalize'
normalizer.tone_normalization(text)
normalizer.remove_redundant_dots(text)
normalizer.remove_emojis(text)
normalizer.basic_normalizer(
    text,
    case_folding=True,
    mode='lower',
    tone_normalization=True,
    remove_emoji=False,
    split_emoji=True
)
```

#### EmojiHandler

```python
emoji_handler = EmojiHandler()

# Methods
emoji_handler.detect_emoji(text)
emoji_handler.split_emoji_text(text)
emoji_handler.split_emoji_emoji(text)
emoji_handler.remove_emojis(text)
```

#### ViSoLexNormalizer

```python
normalizer = ViSoLexNormalizer(model_repo=None, device='cpu')

# Methods
normalizer.normalize_sentence(input_str, detect_nsw=False)
```

#### NswDetector

```python
detector = NswDetector(model_repo=None, device='cpu')

# Methods
detector.detect_nsw(input_str)
detector.concatenate_nsw_spans(nsw_spans)
```

---

## ğŸ”¬ Examples

Xem file [test_toolkit.ipynb](test_toolkit.ipynb) Ä‘á»ƒ cÃ³ cÃ¡c vÃ­ dá»¥ chi tiáº¿t vÃ  Ä‘áº§y Ä‘á»§ hÆ¡n.

---

## ğŸ“ Citation

Náº¿u báº¡n sá»­ dá»¥ng ViSoNorm trong nghiÃªn cá»©u, vui lÃ²ng trÃ­ch dáº«n:

```bibtex
@misc{visonorm2024,
  title={ViSoNorm: Vietnamese Social Media Lexical Normalization Toolkit},
  author={Ha Dung Nguyen},
  year={2024},
  url={https://github.com/AnhHoang0529/visonorm},
  note={Available at https://huggingface.co/visolex}
}
```

---
## ğŸ“„ License

This project is licensed under the MIT License - see the [LICENSE](LICENSE) file for details.

---

## ğŸ‘¥ Authors

- **Anh Thi-Hoang Nguyen** - *Maintainer* - [anhnth@uit.edu.vn](mailto:anhnth@uit.edu.vn)
- **Ha Dung Nguyen** - *Maintainer* - [dungngh@uit.edu.vn](mailto:dungngh@uit.edu.vn)

---

## ğŸ™ Acknowledgments

- HuggingFace for hosting models and providing the transformers library
- The Vietnamese NLP community for datasets and feedback

---

## ğŸ“ Contact & Support

- **GitHub Issues**: [https://github.com/AnhHoang0529/visonorm/issues](https://github.com/AnhHoang0529/visonorm/issues)
- **Email**: anhnth@uit.edu.vn
- **HuggingFace**: [https://huggingface.co/visolex](https://huggingface.co/visolex)

---

## ğŸ”— Links

- **GitHub Repository**: [https://github.com/AnhHoang0529/visonorm](https://github.com/AnhHoang0529/visonorm)
- **PyPI Package**: [https://pypi.org/project/visonorm/](https://pypi.org/project/visonorm/)
- **HuggingFace Hub**: [https://huggingface.co/visolex](https://huggingface.co/visolex)
- **Documentation**: [https://github.com/AnhHoang0529/visonorm](https://github.com/AnhHoang0529/visonorm)
